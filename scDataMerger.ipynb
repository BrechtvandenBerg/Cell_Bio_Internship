{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate the base directory of the data\n",
    "base_dir = \"/scratch/bvdberg/SoloTE/\"\n",
    "\n",
    "# Use glob to find directories matching the pattern\n",
    "directories = glob.glob(\n",
    "    os.path.join(base_dir, \"run_*/\", \"*_SoloTE_output/\", \"*_locustes_MATRIX\")\n",
    ")\n",
    "anndata = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in directories:\n",
    "    # Set the wildcard per directory\n",
    "    wildcard = os.path.basename(directory)\n",
    "    identifier = str(wildcard.split(\"_locustes_MATRIX\")[0])\n",
    "    \n",
    "    # Skip directories with an empty identifier\n",
    "    if not identifier:\n",
    "        continue\n",
    "\n",
    "    # Check if the required files exist in the directory\n",
    "    matrix_file = os.path.join(directory, \"matrix.mtx\")\n",
    "    barcodes_file = os.path.join(directory, \"barcodes.tsv\")\n",
    "    features_file = os.path.join(directory, \"features.tsv\")\n",
    "\n",
    "    if (\n",
    "        os.path.exists(matrix_file)\n",
    "        and os.path.exists(barcodes_file)\n",
    "        and os.path.exists(features_file)\n",
    "    ):\n",
    "        # Create a new AnnData object for each directory\n",
    "        adata = sc.AnnData()\n",
    "\n",
    "        # Read the matrix using scanpy\n",
    "        adata = sc.read_mtx(matrix_file)\n",
    "        adata = adata.transpose()\n",
    "\n",
    "        # Read barcodes and features using pandas\n",
    "        barcodes = pd.read_csv(barcodes_file, sep=\"\\t\", header=None, names=[\"barcode\"])\n",
    "        features = pd.read_csv(features_file, sep=\"\\t\", header=None, names=[\"gene_name\"])\n",
    "\n",
    "        # Set obs_names and var_names\n",
    "        adata.obs_names = barcodes[\"barcode\"]\n",
    "        adata.var_names = features[\"gene_name\"]\n",
    "\n",
    "        anndata[identifier] = adata\n",
    "\n",
    "    else:\n",
    "        print(f\"Required files not found in directory: {directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mbshome/bvdberg/miniconda3/envs/scanpy/lib/python3.11/site-packages/anndata/_core/anndata.py:1838: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "# Combine the adata sets to one data set with the Concatenate function, we use 'outer' to preserve as much data as possible. Missing variablles will become NaN values\n",
    "combined_adata = ad.concat(anndata, label=\"dataset_origin\", join=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the data to make it comparable to a whitelisted h5ad formatted file, by manipulating the 'dataset origin' column\n",
    "combined_adata.obs.index = combined_adata.obs['dataset_origin'].str[1:] + '_' + combined_adata.obs.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adata.write_h5ad(\"combined_bonemarrow_sets.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 14434 × 2000\n",
       "    obs: 'nCount_RNA', 'nFeature_RNA', 'sampleID', 'tissue', 'model', 'age', 'model_age', 'mouseID', 'doublet_scores', 'percent.mt', 'percent.ribo', 'percent.hb', 'percent.hist', 'S.Score', 'G2M.Score', 'group_umap_sub', 'annotation_lv0', 'annotation_lv1', 'annotation_lv2', 'annotation_lv3', 'phase'\n",
       "    var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable'\n",
       "    obsm: 'X_tsne', 'X_umap', 'X_umap_sub', 'X_umap_tissue'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitelist_anndata = ad.read_h5ad(\"bonemarrow_m.h5ad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mbshome/bvdberg/miniconda3/envs/scanpy/lib/python3.11/site-packages/anndata/_core/anndata.py:1113: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if not is_categorical_dtype(df_full[k]):\n"
     ]
    }
   ],
   "source": [
    "# Subset the anndata based on the whitelist\n",
    "filtered_anndata = combined_adata[combined_adata.obs.index.isin(whitelist_anndata.obs.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy metadata from the whitelist to the filtered dataset\n",
    "filtered_anndata.obs = whitelist_anndata.obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the 'TE_type' column\n",
    "filtered_anndata.var['te_type'] = 'GENE'\n",
    "\n",
    "# Create a mask based on the structure you want to match\n",
    "mask = filtered_anndata.var_names.str.count(':') > 1\n",
    "\n",
    "# Apply the structure-based modification to matching entries\n",
    "matching_entries = filtered_anndata.var_names[mask]\n",
    "matching_entries = matching_entries.astype(str).str.split(':').str[2]\n",
    "matching_entries = matching_entries.str.split('|').str[0]\n",
    "\n",
    "# Update the 'te_type' column for matching entries\n",
    "filtered_anndata.var['te_type'][mask] = matching_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_anndata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Latitude\\OneDrive\\Bureaublad\\Workspace\\CellBio_Internship\\scDataMerger.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Latitude/OneDrive/Bureaublad/Workspace/CellBio_Internship/scDataMerger.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m filtered_anndata\u001b[39m.\u001b[39mwrite_h5ad(\u001b[39m\"\u001b[39m\u001b[39mwhitelisted_bonemarrow.h5ad\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/Latitude/OneDrive/Bureaublad/Workspace/CellBio_Internship/scDataMerger.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m filtered_anndata\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_anndata' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_anndata.write_h5ad(\"whitelisted_bonemarrow.h5ad\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy",
   "language": "python",
   "name": "scanpy"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
